#    Highland Statistics Ltd.
#    www.highstat.com

#    This program is distributed in the hope that it will be useful,
#    but WITHOUT ANY WARRANTY; without even the implied warranty of
#    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#    GNU General Public License for more details.


#Code for Chapter 2 in Zuur, Saveliev, Ieno (2012)
#Zero Inflated models and GLMM 


#Set the working directory

setwd("Z:/Users/Highstat/applicat/HighlandStatistics/Books/Book4/Data/Owls")

#Set the directory for WInBUGS
WinBugsDir <- "C:/Program Files/WinBUGS14/"

#Load the owl data
Owls <- read.table("Owls.txt", header=TRUE)
names(Owls)
str(Owls)

# "FoodTreatment"      "SexParent"
# "ArrivalTime"        "SiblingNegotiation" "BroodSize"
# "NegPerChick"

Owls$NCalls <- Owls$SiblingNegotiation      



#Section 2.1
#Fig 2.2
library(mgcv)
G1 <- gamm(NCalls ~ FoodTreatment + s(ArrivalTime), 
           random = list(Nest =~ 1), 
           data = Owls)
plot(G1$gam, cex.lab = 1.5)




#Section 2.3 Data exploration
table(Owls$Nest)
plot(table(Owls$Nest), type = "h")
#Potential trouble with 2 nests with only 4 observations


Owls2 <- Owls[Owls$Nest!="Chevroux" & 
                Owls$Nest!="Forel" & 
                Owls$Nest!="GDLV" & 
                Owls$Nest!="SEvaz",]
Owls2$Nest <- factor(Owls2$Nest)



#Figure 2.4
plot.design(NCalls ~ FoodTreatment + SexParent + Nest ,
            data = Owls2,
            cex.lab = 1.5)
            

#Figure 2.5
interaction.plot(Owls2$FoodTreatment, Owls2$SexParent,
                 Owls2$NCalls, xlab="FoodTreatment",
                 ylab="Sibbling negotiation",
                 cex.lab = 1.5)




#Figure 2.6
library(lattice)
xyplot(NCalls ~ ArrivalTime | SexParent * FoodTreatment,
       data = Owls2, cex.lab = 1.5,
       ylab = "Sibbling negotiation", xlab = "Arrival time (hours)",
         panel=function(x, y){
           panel.grid(h = -1, v = 2)
           panel.points(x, y, col = 1)
           panel.loess(x, y, span = 0.3, col = 1, lwd = 2)})


#Figure 2.7
xyplot(Ycoord ~ Xcoord, aspect = "iso", col = 1,
       xlab = "X coordinate",
       ylab = "Y coordinate",
       data = Owls2,
       pch = 16)


#Figure 2.8
xyplot(NCalls ~ ArrivalTime | Nest, type="h",
       subset = (FoodTreatment == "Satiated"),
       data = Owls2, col = 1)

#Figure 2.9
xyplot(NCalls ~ ArrivalTime | Nest, type="h",
       subset = (FoodTreatment == "Deprived"),
       data = Owls2, col = 1)



#Section 2.4
library(lme4)
Owls2$LogBroodSize <- log(Owls2$BroodSize)

M1 <- glmer(NCalls ~ SexParent * FoodTreatment +
                         SexParent * ArrivalTime +
                         offset(LogBroodSize) +
                         (1| Nest),
                         family = poisson, data = Owls2)
#See ongoing discussions on mixed modelling mailing list regarding
#warning messages
summary(M1)
E1 <- residuals(M1)
p1 <- length(fixef(M1)) + 1              #The +1 is due to the variance of the random effect 
Overdisp1 <- sum(E1^2) / (nrow(Owls2) - p1)
Overdisp1
#Difference with value in book.
#I guess this is 3 years of further lme4 development
#The book was written in 2011/2012



#Section 2.4.3
##############################################################
#Simulate some data to illustrate the essential part of a GLMM
##############################################################
set.seed(12345)

#Choose N, alpha and beta
N <- 300
X<-runif(N,0,5)
alpha <- 3
beta  <- -1

#Simulate some Poisson data and plot it
eta <- alpha + beta * X
mu <- exp(eta)
Y <- rpois(N, lambda = mu)
plot(x=X, y=Y)

#Apply a Poisson GLM to see whether we get similar estimated values
M1 <- glm(Y ~ X, family = poisson)
summary(M1)


#Now simulate a random intercept a_i, and add it to the data.
#Also create a variable that we can use in the models for this random intercept
a1 <- rnorm(20, mean = 0, sd = 0.1)
a  <- rep(a1, each = 15)
RE <- rep(1:20, each = 15)

ShowWhatWeDo <- cbind(eta,mu,Y,a,RE)
head(ShowWhatWeDo,30)


#Now add the random intercept to the predictor function,
#and sample again Poisson data. These will be more noisy
eta1 <- alpha + beta * X + a
mu1 <- exp(eta1)
Y1 <- rpois(N, lambda = mu1)

plot(x=X, y=Y1)
plot(Y,Y1)


#Now apply a random intercept GLMM with Poisson distribution
library(lme4)
M2 <- glmer(Y1 ~ X + (1|RE) , family = poisson)
summary(M2)

#Check for overdispersion
E2 <- resid(M2, type = "pearson")
N <- length(Y1)
p <- length(fixef(M2)) + 1
sum(E2^2) / (N - p)
#That is all perfect!




#Now add a latent term:
#Y_ij = alpha + fixed stuff + a_i + eps_ij
#a_i    ~ N(0, sigma^2_a)
#eps_ij ~ N(0, sigma^2_eps)

#First apply this model on the Y1 data...and the 
#estimated variance of Eps should be small!
Eps <- 1:length(Y1)
M3 <- glmer(Y1 ~ X + (1|RE) + (1|Eps) , family = poisson)
summary(M3)

E3 <- resid(M3, type = "pearson")
p3 <- length(fixef(M3)) + 2
sum(E3^2)/(N-p3)
#That looks all ok
#And apply a likelihood ratio test...hopefully it is not significant!
anova(M2, M3)
#Ok


#Now generate overdispersed count data
#Y_ij = alpha + fixed stuff + a_i + eps_ij
#a_i    ~ N(0, sigma^2_a)
#eps_ij ~ N(0, sigma^2_eps)

#Take: sigma^2_a   = 0.1
#      sigma^2_eps = 0.4

NoiseEps <- rnorm(N, mean = 0, sd = 0.4)
a1 <- rnorm(20, mean = 0, sd = 0.1)
a  <- rep(a1, each = 15)
RE <- rep(1:20, each = 15)

eta <- alpha + beta * X + a + NoiseEps
mu  <- exp(eta)
Y2  <- rpois(N, lambda = mu)

plot(x=X, y = Y2)
plot(Y,Y2)
plot(Y1,Y2)


#Now apply the random intercept Poisson GLMM on these data.
#This should give an overdispersed model
M4 <- glmer(Y2 ~ X + (1|RE), family = poisson)
summary(M4)

#Plot fitted values versus residuals
plot(residuals(M4) ~ fitted(M4))
#Add smoother
rvec <- seq(0,30,length=101)
Sm1 <- loess(residuals(M4) ~ fitted(M4))
lines(rvec, predict(Sm1, newdata = rvec), col = 2, lwd = 2)
abline(h = 0)



E4 <- resid(M4, type = "pearson")
p4 <- length(fixef(M4)) + 1
sum(E4^2)/(N-p4)
#Depends on the random numbe generator but it tends to be overdispersed
#Could use bigger value for the sigma_eps
#As a test...take sigma_eps = 1.4 in the random number generate above


#Now...if we fit the random intercept Poisson GLMM with extra dispersion 
#parameter, we get: 
M5 <- glmer(Y2 ~ X + (1|RE) + (1|Eps) , family = poisson)
summary(M5)

E5 <- resid(M5, type = "pearson")
p5 <- length(fixef(M5)) + 2
sum(E5^2)/(N-p5)
#Hmmm...depends on the actual simulated values....but it seems
#that the extra random term consumes a lot of info!

#Compare the last two models:
anova(M4, M5)




###END OF SIMULATION STUDIES##################################



#Subsection 2.4.4
Eps <- 1:nrow(Owls2)
M2 <- glmer(NCalls ~ SexParent * FoodTreatment +
              SexParent * ArrivalTime +
              offset(LogBroodSize) +
              (1| Nest) + (1|Eps),
            family = poisson, data = Owls2)

M1 <- glmer(NCalls ~ SexParent * FoodTreatment +
              SexParent * ArrivalTime +
              offset(LogBroodSize) +
              (1| Nest),
            family = poisson, data = Owls2)
anova(M1,M2)
#################################################





################################################
#Section 2.6
################################################


#Function to convert a vector into a matric for 2-way nested GLMMs
Vec2Mat <- function(FNest, FY){
   AllNests <- levels(FNest)
   NNest <- length(unique(FNest))
   MaxObs <- max(table(FNest))
   Y.ij <- matrix(NA,nrow=MaxObs, ncol= NNest)
   for (i in 1:NNest) {
     Selection <- FNest==AllNests[i]
     ni <- sum(Selection)
     Y.ij[1:ni,i] <- FY[Selection]
   }
   Y.ij
}

Mat2Vec <- function(NumInNest, FY){
   nc <- ncol(FY)
   N <-  sum(NumInNest)
   Y <- vector(length = N)
   a1 <- 1   
   for (i in 1:nc) {
     a2 <- a1 + NumInNest[i] -1
     Y[a1:a2] <- FY[1:NumInNest[i],i]
     a1 <- a1 + NumInNest[i]
   }
   Y
}




NCalls.ij           <- Vec2Mat(Owls2$Nest, Owls2$NCalls)
ArrivalTime.ij      <- Vec2Mat(Owls2$Nest, Owls2$ArrivalTime-mean(Owls2$ArrivalTime))
LBroodSize.ij       <- Vec2Mat(Owls2$Nest, Owls2$LogBroodSize)
SexParent.ij        <- Vec2Mat(Owls2$Nest, Owls2$SexParent)
iSexParent.ij       <- SexParent.ij -1
FoodTreatment.ij    <- Vec2Mat(Owls2$Nest, Owls2$FoodTreatment)
iFoodTreatment.ij   <- FoodTreatment.ij - 1

Owls2$Cen.AT <- Owls2$ArrivalTime-mean(Owls2$ArrivalTime)

NObservationsInNest <- as.numeric(tapply(Owls2$NCalls, FUN = length, INDEX = Owls2$Nest))




#Bundle data
win.data <- list(NCalls             = NCalls.ij, 
                ArrivalTime         = ArrivalTime.ij,
                LBroodSize          = LBroodSize.ij,
                NNest               = length(levels(Owls2$Nest)),
                NObservationsInNest = NObservationsInNest,
                iSexParent          = iSexParent.ij,
                iFoodTreatment      = iFoodTreatment.ij)




#####################################
#Model
# The code below contains slightly more things than in the 
# book, e.g. the Pearson residuals etc. 
sink("modelglm.txt")
cat("
model{

#Priors
for (i in 1:5) { beta[i]  ~ dnorm(0, 0.001) }
alpha ~ dnorm(0, 0.001)

#Likelihood
for (i in 1:NNest) {
 for (j in 1:NObservationsInNest[i]) {
   NCalls[j,i] ~ dpois(mu[j,i])   
   log(mu[j,i]) <- max(-20, min(20, eta[j,i]))
   eta[j,i] <- alpha + beta[1] * iSexParent[j,i] +
                       beta[2] * iFoodTreatment[j,i] +
                       beta[3] * ArrivalTime[j,i] +
                       beta[4] * iFoodTreatment[j,i] * iSexParent[j,i] +
                       beta[5] * iSexParent[j,i]     * ArrivalTime[j,i] +
                       1 * LBroodSize[j,i]          
  
   #Discrepancy measures
   YNew[j,i] ~ dpois(mu[j,i])
   PRes[j,i]    <- (NCalls[j,i] - mu[j,i]) / sqrt(mu[j,i])
   PResNew[j,i] <- (YNew[j,i] - mu[j,i]) / sqrt(mu[j,i])
   D[j,i]     <- pow(PRes[j,i], 2)
   DNew[j, i] <- pow(PResNew[j,i], 2)
 }
 Fiti[i] <- sum(D[1:NObservationsInNest[i], i])
 FitiNew[i] <- sum(DNew[1:NObservationsInNest[i], i])
}
Fit <- sum(Fiti[1:NNest])
FitNew <- sum(FitiNew[1:NNest])
}
",fill = TRUE)
sink()
#####################################
#

 

#Inits function
inits  <- function () {
  list(
   alpha      = rnorm(1),
   beta       = rnorm(5))  }



#Parameters to estimate
params <- c("alpha","beta", "PRes", "Fit", "FitNew")


#MCMC settings
nc <- 3           #Number of chains
ni <- 100000       #Number of draws from posterior (for each chain)
nb <- 10000         #Number of draws to discard as burn-in
nt <- 100           #Thinning rate



library(R2WinBUGS)

#Start Gibbs sampler
out1 <- bugs(data = win.data,
           inits = inits,
           parameters = params,
           model = "modelglm.txt",
           n.thin = nt,
           n.chains = nc,
           n.burnin = nb,
           n.iter = ni,
           debug = FALSE)
           
          
print(out1, digits = 2)


#Section 2.6.7
Chains <- out1$sims.array[,, beta[1]]

#beta
for (i in 1:5) {
  par(mfrow = c(1,1))
  MyParam <- i   #Change this value from 1 to 5
  Chains <- out1$sims.array[,,paste("beta","[",MyParam,"]", sep = "")]
  plot( Chains[,1], type = "l", col = 1, 
        main = paste("beta", MyParam, sep = ""),
        ylab = "")
  lines(Chains[,2], col = 2)
  lines(Chains[,3], col = 3)
  #win.graph()
}

#Figure 2.15
for (i in 1:5) {
  par(mfrow = c(2,2))
  MyParam <- i   #Change this value from 1 to 5
  Chains <- out1$sims.array[,,paste("beta","[",MyParam,"]", sep = "")]
  acf( Chains[,1], cex.lab = 1.5, main = paste("ACF ", "beta", MyParam," chain 1", sep = ""))
  acf( Chains[,2], cex.lab = 1.5, main = paste("ACF ", "beta", MyParam," chain 2", sep = ""))
  acf( Chains[,3], cex.lab = 1.5, main = paste("ACF ", "beta", MyParam," chain 3", sep = ""))
  #win.graph()
}



#Section 2.6.8
print(out1, digits = 2)

Beta15 <- as.vector(out1$sims.list$beta[,1:5])
ID15   <- rep(c("beta1","beta2","beta3","beta4","beta5"),
              each = nrow(out1$sims.list$beta))

histogram( ~ Beta15 | factor(ID15),
           type = "count" ,
           nint = 100,
           layout = c(1,5),
           xlab = "Posterior distribution",
           col = gray(0.5), 
           ylab = "Frequencies",
           scales = list(alternating = T, 
                         x = list(relation = "same"),
                         y = list(relation = "free")),
           panel = function(x, ...) {
             panel.histogram(x, ...)
             panel.abline(v = 0, lwd = 3, col =2)})





#Section 2.6.9 
#The WInBUGS code already contained the Pearson residuals

E1.mat <- out1$mean$PRes
E1     <- Mat2Vec(NObservationsInNest, E1.mat)

boxplot(E1 ~ Owls2$Nest,
     xlab = "Nest",
     ylab = "Pearson residuals")
abline(0,0, lty = 1, lwd = 1)


#Assess overdispersion
mean(out1$sims.list$Fit > out1$sims.list$FitNew)
#In the book we wrote this just the other way around
#I think this makes more sense; if Fit is always larger
#than FitNew then you have overdispersion.



M2 <- glm(NCalls ~ SexParent * FoodTreatment +
                         SexParent * Cen.AT +
                         offset(LogBroodSize), 
                         family = poisson, data = Owls2)

summary(M2)
#I think I am using 4 more observations in this code, as compared
#to the book. That will explain the differences that we saw earlier.


COMP <- matrix(nrow=6, ncol =4)
colnames(COMP) <- c("beta WinBUGS","sd WinBUGS","beta glm","sd glm")
rownames(COMP) <- c("Intercept", "SexParent.Fem", 
                    "FoodT.Satiated", "ArrivalTime",
                    "SexParent.Fem x FoodT.Satiated",
                    "SexParent.Fem x ArrivalTime")
COMP[,1] <- c(out1$mean$alpha,out1$mean$beta)
COMP[,2] <- c(out1$sd$alpha,out1$sd$beta)
COMP[,3] <- coef(M2)
COMP[,4] <- sqrt(diag(vcov(M2)))

round(COMP,digits = 3)





##########################################################
#Section 2.7 Now fit a Poisson GLMM using the same model
#Add nest as random effect


#####################################
#Model
sink("modelglmm.txt")
cat("
model{

#Priors
for (i in 1:5) { beta[i]  ~ dnorm(0, 0.001) }
alpha ~ dnorm(0, 0.001)
for (i in 1:NNest) {
  a[i] ~ dnorm(0, tau.Nest)
}

tau.Nest <- 1 / (sigma.Nest * sigma.Nest)
sigma.Nest ~ dunif(0,10)
sigma2.Nest <- sigma.Nest * sigma.Nest


#Likelihood
for (i in 1:NNest) {
 for (j in 1:NObservationsInNest[i]) {
    
   #Poisson part 
   NCalls[j,i] ~ dpois(mu[j,i])   
   log(mu[j,i]) <- max(-20, min(20, eta[j,i]))
   eta[j,i] <- alpha + beta[1] * iSexParent[j,i] +
                       beta[2] * iFoodTreatment[j,i] +
                       beta[3] * ArrivalTime[j,i] +
                       beta[4] * iFoodTreatment[j,i] * iSexParent[j,i] +
                       beta[5] * iSexParent[j,i]     * ArrivalTime[j,i] +
                       1 * LBroodSize[j,i] +
                       a[i]      

   #Discrepancy measures
   YNew[j,i] ~ dpois(mu[j,i])
   PRes[j,i]    <- (NCalls[j,i] - mu[j,i]) / sqrt(mu[j,i])
   PResNew[j,i] <- (YNew[j,i]   - mu[j,i]) / sqrt(mu[j,i])
   D[j,i]     <- pow(PRes[j,i], 2)
   DNew[j, i] <- pow(PResNew[j,i], 2)


   ExpY[j,i] <- exp(eta[j,i]) * exp(sigma2.Nest  / 2)
   VarY[j,i] <- exp(eta[j,i]) * (exp(eta[j,i]) *(exp(sigma2.Nest) - 1) * exp(sigma2.Nest) + exp(sigma2.Nest / 2))
   PResEQ[j,i] <- (NCalls[j,i]- ExpY[j,i]) / sqrt(VarY[j,i])
   Disp1[j,i] <- pow(PResEQ[j,i],2)
  
   }
 Disp2[i] <- sum(Disp1[1:NObservationsInNest[i],i])
 Fiti[i] <- sum(D[1:NObservationsInNest[i], i])
 FitiNew[i] <- sum(DNew[1:NObservationsInNest[i], i])
}
Dispersion <- sum(Disp2[1:NNest]) 
Fit <- sum(Fiti[1:NNest])
FitNew <- sum(FitiNew[1:NNest])
}
",fill = TRUE)
sink()
#####################################
#

 

#Inits function
inits  <- function () {
  list(
   alpha      = rnorm(1),
   beta       = rnorm(5),
   a          = rnorm(length(levels(Owls2$Nest)), 0, 1),
   sigma.Nest = rlnorm(1))  }



#Parameters to estimate
params <- c("alpha","beta", "a", "sigma.Nest", 
            "Dispersion", "Fit", "FitNew",
            "PRes")

nc <- 3           #Number of chains
ni <- 100000       #Number of draws from posterior (for each chain)
nb <- 10000         #Number of draws to discard as burn-in
nt <- 100           #Thinning rate

#Start Gibbs sampler
out2 <- bugs(data = win.data,
           inits = inits,
           parameters = params,
           model = "modelglmm.txt",
           n.thin = nt,
           n.chains = nc,
           n.burnin = nb,
           n.iter = ni,
           debug = TRUE)

print(out2, digits = 3)

out2$mean$sigma.Nest
out2$mean$Dispersion/(nrow(Owls))
mean(out2$sims.list$FitNew > out2$sims.list$Fit)
#Small differences due to the 4 extra observations








#Section 2.8
##############################################################
#Simulate some data to illustrate the essential part of a ZIP
##############################################################
set.seed(12345)

beta1 <- 2
beta2 <- 2.5
gamma1 <- 2
N <- 250
X <- runif(N, min = 0, max = 1)

psi <- exp(gamma1) / (1 + exp(gamma1))
psi

W <- rbinom(N, size = 1, prob = 1-psi)
table(W)


mu <- exp(beta1 + beta2 * X)
mu.eff <- W * mu
Y <- rpois(N, lambda = mu.eff)


table(Y)

100 * table(Y) / N


FalseZeros <- W==0
RealZeros  <- Y==0 & W==1

MyPch <- vector(length = length(Y))
MyPch[] <- 1
MyPch[RealZeros] <- 16
plot(X,Y, cex.lab = 1.5)




T1 <- glm(Y ~ X, family = poisson)
summary(T1)
deviance(T1)/ T1$df.res 
sum(resid(T1, type = "pearson")^2) / T1$df.res

par(mfrow = c(2,2))
plot(T1)


library(pscl)
Z1 <- zeroinfl(Y~ X | 1)
summary(Z1)
 

#####################################
#Fit ZIP in WinBUGS
win.data <- list(Y = Y, 
                 X = X,
                 N = length(Y))

#Model
sink("ziptest.txt")
cat("
model{

#Priors
beta[1]  ~ dnorm(0, 0.01) 
beta[2]  ~ dnorm(0, 0.01) 
gamma1 ~ dnorm(0, 0.01) 

#Likelihood
for (i in 1:N) {
   #Binary part
   W[i] ~ dbern(psi.min1)
   #Count process
   Y[i] ~ dpois(mu.eff[i])
   mu.eff[i]  <- W[i] * mu[i]
   log(mu[i]) <- eta[i]
   eta[i]     <- beta[1] + beta[2] * X[i]       
 }
 psi.min1   <- 1 - psi
 logit(psi) <- gamma1
}
",fill = TRUE)
sink()
#####################################
#

W        <- Y
W[Y > 0] <- 1


#Inits function
inits  <- function () {
  list(
   beta   = rnorm(2),
   gamma1 = rnorm(1),
   W      = W)  }



#Parameters to estimate
params <- c("beta", "gamma1")


#MCMC settings
nc <- 3           #Number of chains
ni <- 100000       #Number of draws from posterior (for each chain)
nb <- 10000         #Number of draws to discard as burn-in
nt <- 100           #Thinning rate


#Start Gibbs sampler
ZipSim1 <- bugs(data = win.data,
           inits = inits,
           parameters = params,
           model = "ziptest.txt",
           n.thin = nt,
           n.chains = nc,
           n.burnin = nb,
           n.iter = ni,
           debug = TRUE)

print(ZipSim1, digits = 2)








#################################################
#Section 2.9 
#The code below contains some extra lines, e.g. calculation of
#the likelihood function of a ZIP. This is explained later in the
#chapter.
win.data <- list(NCalls             = NCalls.ij, 
                 ArrivalTime         = ArrivalTime.ij,
                 LBroodSize          = LBroodSize.ij,
                 NNest               = length(levels(Owls2$Nest)),
                 NObservationsInNest = NObservationsInNest,
                 iSexParent          = iSexParent.ij,
                 iFoodTreatment      = iFoodTreatment.ij)

#Model
sink("modelzipglmm.txt")
cat("
model{

#Priors
for (i in 1:5) { beta[i]  ~ dnorm(0, 0.001) }
alpha  ~ dnorm(0, 0.001)
gamma1 ~ dnorm(0, 0.001)

for (i in 1:NNest) {
  a[i] ~ dnorm(0, tau.Nest)
}

tau.Nest <- 1 / (sigma.Nest * sigma.Nest)
sigma.Nest ~ dunif(0,10)
sigma2.Nest <- sigma.Nest * sigma.Nest

#Likelihood
for (i in 1:NNest) {
 for (j in 1:NObservationsInNest[i]) {
   #Logit part
   W[j,i] ~ dbern(psi.min1)
    
   #Poisson part 
   NCalls[j,i] ~ dpois(eff.mu[j,i])   
   eff.mu[j,i]  <- W[j,i] * mu[j,i]
   log(mu[j,i]) <- max(-20, min(20, eta[j,i]))
   eta[j,i] <- alpha + beta[1] * iSexParent[j,i] +
                       beta[2] * iFoodTreatment[j,i] +
                       beta[3] * ArrivalTime[j,i] +
                       beta[4] * iFoodTreatment[j,i] * iSexParent[j,i] +
                       beta[5] * iSexParent[j,i]     * ArrivalTime[j,i] +
                       1 * LBroodSize[j,i] +
                       a[i]   
   EZip[j,i]   <- mu[j,i] * (1 - psi)
   VarZip[j,i] <- (1 - psi) * (mu[j,i] + psi * pow(mu[j,i], 2))
   PRES[j,i] <- (NCalls[j,i] - EZip[j,i]) / sqrt(VarZip[j,i])   
      
   #log-likelihood
   lfd0[j,i] <- log(psi + (1 - psi) * exp(-mu[j,i]))
   lfd1[j,i] <- log(1 - psi) + NCalls[j,i] * log(mu[j,i])  - mu[j,i]  - loggam(NCalls[j,i]+1)
   L[j,i]    <- (1-W[j,i]) * lfd0[j,i] + W[j,i] * lfd1[j,i]
 }
   Li[i] <- sum(L[1:NObservationsInNest[i],i])
 
 }
 psi.min1 <- min(0.99999, max(0.00001,(1 - psi)))
 eta.psi <- gamma1  
 logit(psi) <- max(-20, min(20, eta.psi))    
 dev <- -2 * sum(Li[1:NNest])

}
",fill = TRUE)
sink()
#####################################
#

 
 
MyW                    <- NCalls.ij
MyW[NCalls.ij > 0]     <- 1
MyW
#


#Inits function
inits  <- function () {
  list(
   alpha      = rnorm(1),
   beta       = rnorm(5),
   a          = rnorm(length(levels(Owls2$Nest)), 0, 1),
   sigma.Nest = rlnorm(1),
   W          = MyW,
   gamma1     = rnorm(1) )  }



#Parameters to estimate
params <- c("alpha","beta", "a", "sigma.Nest", 
            "gamma1", "PRES", "dev")

#MCMC settings
nc <- 3           #Number of chains
ni <- 100000       #Number of draws from posterior (for each chain)
nb <- 10000         #Number of draws to discard as burn-in
nt <- 100           #Thinning rate

#Start Gibbs sampler
out3 <- bugs(data = win.data,
           inits = inits,
           parameters = params,
           model = "modelzipglmm.txt",
           n.thin = nt,
           n.chains = nc,
           n.burnin = nb,
           n.iter = ni,
           debug = TRUE)

print(out3, digits = 2)


#Figure 2.19
out3$mean$sigma.Nest
hist(out3$sims.list$gamma1, breaks = 50,
    main = "",
    xlab = "gamma1 values",
    ylab = "Frequency",
    cex.lab = 1.5)


Probs <- c(0.025, 0.5, 0.975)
MyOUT <- matrix(nrow = 6, ncol = 3)
for (i in 1:5){ 
 MyOUT[i,] <- quantile(out3$sims.list$beta[,i], probs = Probs)
 }
MyOUT[6,]<- quantile(out3$sims.list$sigma.Nest, probs = Probs)
colnames(MyOUT) <- c("2.5%","median","97.5%")
rownames(MyOUT) <- c("beta1","beta2","beta3","beta4","beta5","sigma.Nest") 
round(MyOUT, digits = 3) 





out <- out3



#Figure 2.20A
E3.mat <- out3$mean$PRES
E3 <- Mat2Vec(NObservationsInNest, E3.mat)

plot(x=Owls2$ArrivalTime, y = E3,
     xlab = "Arrival time",
     ylab = "Pearson residuals")
abline(0,0, lty = 1, lwd = 1)

library(mgcv)
Temp <- gam(E3 ~ s(ArrivalTime), data = Owls2)
summary(Temp)
MyData <- data.frame(ArrivalTime = seq(min(Owls2$ArrivalTime),
                                       max(Owls2$ArrivalTime),
                                       length =100))
P1 <- predict(Temp, newdata = MyData, se = TRUE)
lines(MyData$ArrivalTime , P1$fit, lwd = 3)
lines(MyData$ArrivalTime , P1$fit + 2 * P1$se.fit, lwd = 3, lty = 2)
lines(MyData$ArrivalTime , P1$fit - 2 * P1$se.fit, lwd = 3, lty = 2)



library(gstat)
#This graph is not in the chapter
mydata<-data.frame(E3, Owls2$Xcoord, Owls2$Ycoord)
coordinates(mydata) <- c("Owls2.Xcoord", "Owls2.Ycoord")
bubble(mydata, "E3",
       col = "black",
       main = "Residuals",
       xlab = "X-coordinates",
       ylab = "Y-coordinates")

AllNest <- levels(Owls2$Nest)
Z <- matrix(nrow = 24, ncol = 2)
X <- cbind(Owls2$Xcoord, Owls2$Ycoord)
for (i in 1:24) {
    Nesti <- AllNest[i]
    Zi <- Owls2[Owls2$Nest == Nesti,]
    Z[i,] <- c(Zi$Xcoord[1],Zi$Ycoord[1])
    }
Z


#Figure 2.20B
hist(dist(Z, method = "euclidean"),
     main = "",
     xlab = "Distances between sites")
     

#Figure 2.21
Vario1 = variogram(E3 ~ 1, mydata, 
                   cressie = TRUE,
                   cutoff = 10000)
plot(Vario1, pch = 16, 
     col = 1, 
     cex = 2,
     cex.lab = 1.5)



#Section 2.10 Calculate the DIC for 
dev.mean<-out3$mean$dev
alpha <- out3$mean$alpha
beta1 <- out3$mean$beta[1]
beta2 <- out3$mean$beta[2]
beta3 <- out3$mean$beta[3]
beta4 <- out3$mean$beta[4]
beta5 <- out3$mean$beta[5]
a     <- out3$mean$a

source(file = "GetLogLik.r")
Dhat <- GetLogLik(alpha, beta1, beta2, beta3, beta4, beta5, gamma1, a, out3, win.data)

cat("Dbar=",model.Dbar<-dev.mean,"\n")
cat("Dhat=",model.Dhat<-Dhat,"\n")
cat("pD=  ",model.pD  <-model.Dbar - model.Dhat,"\n")
cat("DIC= ",model.DIC <-model.Dbar + model.pD,"\n")
#End of DIC code

